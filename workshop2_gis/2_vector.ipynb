{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original notebook by [Patrick Gray](https://github.com/patrickcgray)\n",
    "\n",
    "\n",
    "vector data in python using GeoPandas\n",
    "=========================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The *OGR* library is a companion library to *GDAL* that handles vector data capabilities, including information queryies, file conversions, rasterization of polygon features, polygonization of raster features, and much more. It handles popular formats including the *ESRI Shapefile*, *Keyhole Markup Language*, *PostGIS*, and *SpatiaLite*. For more information on how *OGR* came about and how it relates to *GDAL*, see here: http://trac.osgeo.org/gdal/wiki/FAQGeneral#WhatisthisOGRstuff.\n",
    "\n",
    "In this tutorial we'll be working with: \n",
    "* [Shapely](https://shapely.readthedocs.io/en/stable/manual.html): `shapely` does things like buffers, unions, intersections, centroids, convex hulls, and lots more.\n",
    "  * `shapely` is a BSD-licensed Python package for manipulation and analysis of planar geometric objects. It is based on the widely deployed GEOS (the engine of PostGIS) and JTS (from which GEOS is ported) libraries. Shapely is not concerned with data formats or coordinate systems, but can be readily integrated with packages that are.\n",
    "* [Fiona](https://fiona.readthedocs.io/en/latest/): `fiona` does reading and writing data formats.\n",
    " * `fiona` is OGR's neat and nimble API for Python programmers. It focuses on reading and writing data in standard Python IO style and relies upon familiar Python types and protocols such as files, dictionaries, mappings, and iterators instead of classes specific to OGR. `fiona` can read and write real-world data using multi-layered GIS formats and zipped virtual file systems and integrates readily with other python GIS packages such as `pyproj`, `Rtree`, and `Shapely`.\n",
    "* [Geopandas](http://geopandas.org/): GeoPandas is an open source project to make working with geospatial data in python easier. \n",
    "  * GeoPandas extends the datatypes used by pandas to allow spatial operations on geometric types. Geometric operations are performed by shapely. Geopandas further depends on fiona for file access and descartes and matplotlib for plotting.\n",
    "  * The goal of GeoPandas is to make working with geospatial data in python easier. It combines the capabilities of pandas and shapely, providing geospatial operations in pandas and a high-level interface to multiple geometries to shapely. GeoPandas enables you to easily do operations in python that would otherwise require a spatial database such as PostGIS.\n",
    "  \n",
    "Let's explore shapely a bit by creating some shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely\n",
    "from shapely import geometry\n",
    "from shapely.geometry import shape, Point, LineString, Polygon\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = LineString([(0, 0), (1, 1), (1,2), (2,2)])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = LineString([(0, 0), (1, 1), (2,1), (2,2)])\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these two lines created we can run some geospatial operations on them like an intersection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = b.intersection(a)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can buffer shapes too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Point(1, 1)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = c.buffer(1.5)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do intersections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Point(2, 1).buffer(1.5)\n",
    "c.intersection(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can do a union instead of an intersection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.union(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've just been using the default plotting in Jupyter notebooks. Let's shift now to plotting with matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLUE = '#6699cc'\n",
    "GRAY = '#999999'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "x, y = c.union(d).exterior.xy # find all the x and y points in the shape\n",
    "ax.plot(x, y, color=BLUE, linewidth=3, solid_capstyle='round')\n",
    "ax.set_aspect('equal') # make the axes equal so the shape isn't distorted\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is of course just a taste. You can do all sorts of cool geometric operations with shapely.\n",
    "\n",
    "We'll now use an *ESRI Shapefile* that contains training data I collected for the example image we've been working on.\n",
    "\n",
    "## Opening an *ESRI Shapefile*\n",
    "\n",
    "Just like *GDAL* in `rasterio`, *OGR* in `fiona` abstracts the file formats so that we can use the same code for any format. It employs the same concept of a *dataset* object which we can gather information from:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using fiona to import shapefiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "# Open the dataset from the file\n",
    "shapefile = fiona.open('./data/rcr/rcr_landcover.shp')\n",
    "# Make sure the dataset exists -- it would be None if we couldn't open it\n",
    "if not shapefile:\n",
    "    print('Error: could not open shapefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our Shapefile read in, we can look at some of its properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's get the driver from this file\n",
    "driver = shapefile.driver\n",
    "print('Dataset driver is: {n}\\n'.format(n=driver))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### How many features are contained in this Shapefile?\n",
    "feature_count = len(shapefile)\n",
    "print('The shapefile has {n} feature(s)\\n'.format(n=feature_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### What is the shapefiles's projection?\n",
    "# Get the spatial reference\n",
    "spatial_ref = shapefile.crs\n",
    "print('The shapefiles spatial ref is:\\n', spatial_ref, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pull out a specific feature from the shapefile\n",
    "feature = shapefile[0]\n",
    "\n",
    "### What is the features's geometry? is it a point? a polyline? a polygon?\n",
    "geometry = feature['geometry']['type']\n",
    "print(\"The features's geometry is: {geom}\".format(geom=geometry))\n",
    "\n",
    "### How many properties are in the shapefile, and what are their names?\n",
    "properties = feature[\"properties\"].keys()\n",
    "\n",
    "# How many fields\n",
    "field_count = len(properties)\n",
    "print('Layer has {n} fields'.format(n=field_count))\n",
    "\n",
    "# What are their names?\n",
    "print('Their names are: ')\n",
    "for prop in properties:\n",
    "    print('\\t{name}'.format(name=prop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can get a quick view of all of this\n",
    "shapefile.meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shapefile is a list of features, which can be accessed like any python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = shapefile[0]\n",
    "feature # The result is a Python dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As all dictionaries in Python, there are keys and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('id: ', feature['id']) #gives the id\n",
    "print('Classname: ', feature['properties']['Classname']) # gives the value of the classname attribute\n",
    "\n",
    "print('\\ngeometry: ', feature['geometry']) # gives the geometry, GeoJSON format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to transform this geometry into a shapely geometry use the shape function that we imported earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapely_shape = shape(feature['geometry'])\n",
    "print(type(shapely_shape))\n",
    "\n",
    "shapely_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll come back to this set of training features later!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bringing in the real power tools: `geopandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geopandas takes the tools we have seen so far to the next level.\n",
    "\n",
    "The goal of GeoPandas is to make working with geospatial data in python easier. It combines the capabilities of pandas and shapely, providing geospatial operations in pandas and a high-level interface to multiple geometries to shapely. GeoPandas enables you to easily do operations in python that would otherwise require a spatial database such as PostGIS.\n",
    "\n",
    "From the docs:\n",
    "\n",
    "    GeoPandas implements two main data structures, a GeoSeries and a GeoDataFrame. These are subclasses of pandas Series and DataFrame, respectively.\n",
    "\n",
    "    A GeoSeries is essentially a vector where each entry in the vector is a set of shapes corresponding to one observation.\n",
    "\n",
    "    A GeoDataFrame is a tabular data structure that contains a GeoSeries.\n",
    "\n",
    "    The most important property of a GeoDataFrame is that it always has one GeoSeries column that holds a special status. This GeoSeries is referred to as the GeoDataFrame‘s “geometry”. When a spatial method is applied to a GeoDataFrame (or a spatial attribute like area is called), this commands will always act on the “geometry” column\n",
    "\n",
    "Let's show a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "p1 = Polygon([(0, 0), (1, 0), (1, 1)])\n",
    "p2 = Polygon([(0, 0), (1, 0), (1, 1), (0, 1)])\n",
    "p3 = Polygon([(2, 0), (3, 0), (3, 1), (2, 1)])\n",
    "g = gpd.GeoSeries([p1, p2, p3])\n",
    "print(type(g))\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so that is a GeoSeries let's look at a GeoDataFrame using one of the datasets that is packaged with geopandas: a GeoDataFrame of the New York City Boroughs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nybb_path = gpd.datasets.get_path('nybb')\n",
    "boros = gpd.read_file(nybb_path)\n",
    "print(type(boros))\n",
    "boros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot that GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "boros.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty cool! A plot of the NYC Boroughs just like that!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do all the same cool geometric operations to these GeoDataFrames as we could in `shapely`. Here we'll apply [convex hull](https://en.wikipedia.org/wiki/Convex_hull) and color each borough differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "boros.geometry.convex_hull.plot(ax=ax, cmap='hot', edgecolor='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a dataset with some more attributes. GeoPandas comes pre-packaged with a `world` dataset that'll do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "world.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8)) \n",
    "world.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With geopandas you can do filtering just like in any pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all countries with a population greater than 150 million\n",
    "world[(world.pop_est > 150000000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can filter all latitudes greater than 0 leaving only the southern hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "southern_world = world.cx[:, :0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,5)) \n",
    "southern_world.plot(ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do more advanced filtering like combining the countries from each continent and then sorting continents by population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_filtered = world[['continent', 'geometry', 'pop_est']] # filter to only the columns we care about\n",
    "continents = world_filtered.dissolve(by='continent', aggfunc='sum') # dissolve countries\n",
    "continents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also really simple to create Chloropleth maps (maps where the color of each shape is based on the value of an\n",
    "associated variable). \n",
    "\n",
    "Simply use the plot command with the column argument set to the column whose values you want used to assign colors.\n",
    "\n",
    "Let's calculate and plot by GDP per capita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = world[(world.pop_est>0) & (world.name!=\"Antarctica\")]\n",
    "world['gdp_per_cap'] = world.gdp_md_est / world.pop_est\n",
    "world['gdp_per_cap'] = world['gdp_per_cap'] * 1000000 # because it was calcualted in millionths\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "world.plot(column='gdp_per_cap', legend=True, ax=ax, scheme='quantiles') # let's also add a colorbar\n",
    "# and split groups into evenly sized ones with the quantiles keyword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do complicated spatial intersections and unions over large datasets. Let's load a dataset of all glaciers, intersect them with countries, and then sort to find the countries with the most glacial coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data\n",
    "# data available from http://www.naturalearthdata.com/downloads/\n",
    "glaciers = gpd.read_file(\"./data/shapefiles/ne_10m_glaciated_areas.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may take a moment to run because these dataframe joins can involve many operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the area containing both country and glacier\n",
    "glacial_countries = gpd.overlay(world, glaciers, how='intersection') \n",
    "# this will generate an entry for each glacier and country pair\n",
    "# dissolve all matching countries into one\n",
    "glacial_countries = glacial_countries.dissolve(by='name_1', aggfunc='sum')\n",
    "# create a column with area\n",
    "glacial_countries['area'] = glacial_countries.geometry.area\n",
    "# sort the dataframe by area and then display the top 5\n",
    "glacial_countries.sort_values('area', ascending=False).head(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge that glacier area / country dataset back into the world dataset with all the countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glacial_world = world.merge(glacial_countries, right_on='name_1', left_on='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the geometry field which is required for a GeoDataFrame\n",
    "glacial_world['geometry'] = glacial_world['geometry_x']\n",
    "glacial_world = gpd.GeoDataFrame(glacial_world)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot it with all countries being displayed by glacier coverage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "glacial_world.plot(column='area', legend=True, ax=ax, scheme='fisher_Jenks', cmap='BuPu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at some ocean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data available from http://www.naturalearthdata.com/downloads/\n",
    "oceans = gpd.read_file(\"./data/shapefiles/ne_110m_ocean.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oceans.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's overlay the oceans, countries, and glaciers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(10, 6))\n",
    "ax.set_title('Countries and Oceans')\n",
    "oceans.plot(ax=ax, facecolor='lightblue')\n",
    "world.plot(ax=ax, facecolor='lightgray', edgecolor='gray')\n",
    "glaciers.plot(ax=ax, facecolor='blue', edgecolor='darkblue')\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at Anchorage Alaska at 61.2181° N, 149.9003° W\n",
    "\n",
    "Note there are some mismatches between the glacier and land datasets because of the different resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.set_title('Countries and Oceans')\n",
    "oceans.plot(ax=ax, facecolor='lightblue')\n",
    "world.plot(ax=ax, facecolor='lightgray', edgecolor='gray')\n",
    "glaciers.plot(ax=ax, facecolor='blue', edgecolor='darkblue')\n",
    "\n",
    "# specify a location by lat and long\n",
    "ax.set_ylim([55, 65])\n",
    "ax.set_xlim([-155, -145])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS KNOWLEDGE!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read from OGC WFS GeoJSON response into a GeoDataFrame\n",
    "\n",
    "- This example drawn from https://geohackweek.github.io/vector/04-geopandas-intro/\n",
    "\n",
    "#### Don't worry too much about the specifics here, this is an example just to show the power of these common formats for sharing data and getting really informative datasets from all sorts of databases\n",
    "\n",
    "Use an Open Geospatial Consortium (OGC) Web Feature Service (WFS) request to obtain geospatial data from a remote source. OGC WFS is an open geospatial standard.\n",
    "\n",
    "We won’t go into all details about what’s going on. Suffice it to say that we issue an OGC WFS request for all features from the layer named “oa:goainv” found in a GeoServer instance from NANOOS, requesting the response in GeoJSON format. Then we use the geojson package to “load” the raw response (a GeoJSON string) into a geojson feature object (a dictionary-like object).\n",
    "\n",
    "The “oa:goainv” layer is a global dataset of monitoring sites and cruises where data relevant to ocean acidification are collected. It’s a work in progress from the Global Ocean Acidification Observation Network (GOA-ON); for additional information see the GOA-ON Data Portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import requests\n",
    "import geojson\n",
    "import geopandas as gpd\n",
    "\n",
    "# set up request parameters\n",
    "wfs_url = \"http://data.nanoos.org/geoserver/ows\"\n",
    "params = dict(service='WFS', version='1.0.0', request='GetFeature',\n",
    "              typeName='oa:goaoninv', outputFormat='json')\n",
    "\n",
    "# make the request\n",
    "r = requests.get(wfs_url, params=params)\n",
    "wfs_geo = geojson.loads(r.content)\n",
    "\n",
    "# load world basemap\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s examine the general characteristics of this GeoJSON object, including its __geo_interface__ interface, which we discussed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(wfs_geo))\n",
    "print(wfs_geo.keys())\n",
    "print(len(wfs_geo.__geo_interface__['features']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the from_features constructor method to create a GeoDataFrame directly from the geojson.feature.FeatureCollection object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfs_gdf = gpd.GeoDataFrame.from_features(wfs_geo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let’s visualize the data set as a simple map overlay plot; and as an example, display the values for the last feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfs_gdf.plot(ax=world.plot(cmap='Set3', figsize=(10, 6)),\n",
    "             marker='x', markersize=15,  color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kind of data is contained in each of these points? Well let's take a glimpse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfs_gdf.iloc[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
